{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuelemacchia/incremental-learning-image-classification/blob/master/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NzqxHIh4OCdW"
      },
      "source": [
        "# Incremental learning on image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wBHSznCZxpNB"
      },
      "source": [
        "## Libraries and packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4eQ6O12jxMFf",
        "outputId": "3b1c5b66-c04a-4394-eb38-8a57787f85bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.6/dist-packages (7.0.0.post3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xAYXtIdpx0Yy",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "09iWc_oCotu2",
        "outputId": "05bf538d-3479-420d-a8e6-d9a7d9f2ab1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# GitHub credentials for cloning private repository\n",
        "username = ''\n",
        "password = ''\n",
        "\n",
        "# Download packages from repository\n",
        "password = urllib.parse.quote(password)\n",
        "!git clone https://$username:$password@github.com/manuelemacchia/incremental-learning-image-classification.git\n",
        "password = ''\n",
        "\n",
        "!mv -v incremental-learning-image-classification/* .\n",
        "!rm -rf incremental-learning-image-classification README.md"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'incremental-learning-image-classification'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 250 (delta 9), reused 0 (delta 0), pack-reused 231\u001b[K\n",
            "Receiving objects: 100% (250/250), 1.79 MiB | 3.59 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n",
            "renamed 'incremental-learning-image-classification/data' -> './data'\n",
            "renamed 'incremental-learning-image-classification/model' -> './model'\n",
            "renamed 'incremental-learning-image-classification/notebook.ipynb' -> './notebook.ipynb'\n",
            "renamed 'incremental-learning-image-classification/README.md' -> './README.md'\n",
            "renamed 'incremental-learning-image-classification/utils' -> './utils'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPLViftqtC3I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fb3fada9-bf74-4e9c-919e-2104764add9a"
      },
      "source": [
        "from data.cifar100 import Cifar100\n",
        "from model.resnet_cifar import resnet32\n",
        "from model.manager import Manager\n",
        "from utils import plot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j12pgffMR6Qv"
      },
      "source": [
        "## Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwE0x8gkSisn",
        "colab": {}
      },
      "source": [
        "# Directories\n",
        "DATA_DIR = 'data'       # Directory where the dataset will be downloaded\n",
        "\n",
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Dataset\n",
        "RANDOM_STATE = 420      # For reproducibility of results\n",
        "                        # Note: different random states give very different\n",
        "                        # splits and therefore very different results.\n",
        "\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "NUM_BATCHES = 10\n",
        "CLASS_BATCH_SIZE = 10   # Size of batch of classes for incremental learning\n",
        "\n",
        "VAL_SIZE = 0.1          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 64         # Batch size (iCaRL sets this to 128)\n",
        "LR = 0.2                # Initial learning rate\n",
        "                        # iCaRL sets LR = 2. Since they use BinaryCrossEntropy loss it is feasible,\n",
        "                        # in our case it would diverge as we use CrossEntropy loss.\n",
        "MOMENTUM = 0.9          # Momentum for stochastic gradient descent (SGD)\n",
        "WEIGHT_DECAY = 1e-5     # Weight decay from iCaRL\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method\n",
        "                        # Note: this should be at least 3 to have a fair benchmark\n",
        "\n",
        "NUM_EPOCHS = 70         # Total number of training epochs\n",
        "MILESTONES = [49, 63]   # Step down policy from iCaRL (MultiStepLR)\n",
        "                        # Decrease the learning rate by gamma at each milestone\n",
        "GAMMA = 0.2             # Gamma factor from iCaRL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDDdumxRwbdQ"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "skknIP5Jwspm",
        "colab": {}
      },
      "source": [
        "# Define transformations for training\n",
        "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define transformations for evaluation\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5wcci5vi5PIG",
        "outputId": "42abacad-8144-477a-9abd-215a35d83b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "train_dataloaders = [[] for i in range(NUM_RUNS)]\n",
        "val_dataloaders = [[] for i in range(NUM_RUNS)]\n",
        "test_dataloaders = [[] for i in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "\n",
        "  test_subsets = []\n",
        "\n",
        "  for split_i in range(CLASS_BATCH_SIZE):\n",
        "\n",
        "    # Download dataset only at first instantiation\n",
        "    if(run_i+split_i == 0):\n",
        "      download = True\n",
        "    else:\n",
        "      download = False\n",
        "\n",
        "    # Create CIFAR100 dataset\n",
        "    train_dataset = Cifar100(DATA_DIR, train = True, download = download, random_state = RANDOM_STATE+run_i, transform=train_transform)\n",
        "    test_dataset = Cifar100(DATA_DIR, train = False, download = False, random_state = RANDOM_STATE+run_i, transform=test_transform)\n",
        "   \n",
        "    # Subspace of CIFAR100 of 10 classes\n",
        "    train_dataset.set_classes_batch(train_dataset.batch_splits[split_i]) \n",
        "    test_dataset.set_classes_batch([test_dataset.batch_splits[i] for i in range(0, split_i+1)])\n",
        "\n",
        "    # Define train and validation indices\n",
        "    train_indices, val_indices = train_dataset.train_val_split(VAL_SIZE, RANDOM_STATE)\n",
        "    \n",
        "    train_dataloaders[run_i].append(DataLoader(Subset(train_dataset, train_indices), \n",
        "                               batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True))\n",
        "    \n",
        "    val_dataloaders[run_i].append(DataLoader(Subset(train_dataset, val_indices), \n",
        "                                batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True))\n",
        "    \n",
        "    # Dataset with all seen class\n",
        "    test_dataloaders[run_i].append(DataLoader(test_dataset, \n",
        "                               batch_size=BATCH_SIZE, shuffle=True, num_workers=4))           "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-fa0450f2327a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Create CIFAR100 dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifar100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifar100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Subspace of CIFAR100 of 10 classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/data/cifar100.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, download, random_state, transform)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             transform=self.transform)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             raise RuntimeError('Dataset not found or corrupted.' +\n\u001b[1;32m     68\u001b[0m                                ' You can use download=True to download it')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m_check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcalculate_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mNwcf1fpsvm_",
        "colab": {}
      },
      "source": [
        "# Sanity check: visualize a batch of images\n",
        "dataiter = iter(test_dataloaders[0][5])\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "plot.image_grid(images, one_channel=False)\n",
        "unique_labels = np.unique(labels, return_counts=True)\n",
        "unique_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJqnljCV5gJ5"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yya_CxODY4sd",
        "colab": {}
      },
      "source": [
        "# @todo try xavier initialization "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VzVPf2KxKci3",
        "colab": {}
      },
      "source": [
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "# Iterate over runs\n",
        "for train_dataloader, val_dataloader, test_dataloader in zip(train_dataloaders,\n",
        "                                                             val_dataloaders, test_dataloaders):\n",
        "  \n",
        "    \n",
        "    train_loss_history.append({})\n",
        "    train_accuracy_history.append({})\n",
        "    val_loss_history.append({})\n",
        "    val_accuracy_history.append({})\n",
        "    test_accuracy_history.append({})\n",
        "\n",
        "    net = resnet32()  # Define the net\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()  # Define the loss\n",
        "\n",
        "    # In this case we optimize over all the parameters of Resnet\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=LR,\n",
        "                          momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
        "                                               milestones=MILESTONES, gamma=GAMMA)\n",
        "        \n",
        "    \n",
        "    i = 0\n",
        "    for train_split, val_split, test_split in zip(train_dataloader,\n",
        "                                                  val_dataloader, test_dataloader):\n",
        "      \n",
        "        \n",
        "        current_split = \"Split %i\"%(i)\n",
        "        print(current_split)\n",
        "\n",
        "        # Define Manager Object\n",
        "        manager = Manager(DEVICE, net, criterion, optimizer, scheduler,\n",
        "                          train_split, val_split, test_split)\n",
        "\n",
        "        scores = manager.train(NUM_EPOCHS)  # train the model\n",
        "\n",
        "        # score[i] = dictionary with key:epoch, value: score\n",
        "        train_loss_history[-1][current_split] = scores[0]\n",
        "        train_accuracy_history[-1][current_split] = scores[1]\n",
        "        val_loss_history[-1][current_split] = scores[2]\n",
        "        val_accuracy_history[-1][current_split] = scores[3]\n",
        "\n",
        "        # Test the model on classes seen until now\n",
        "        test_accuracy, all_preds = manager.test()\n",
        "\n",
        "        test_accuracy_history[-1][current_split] = test_accuracy\n",
        "\n",
        "        # Uncomment if default resnet has 10 node at last FC layer\n",
        "        #manager.increment_classes(n=10)  # add 10 nodes to last FC layer\n",
        "\n",
        "        i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JWdj0wvu996S",
        "colab": {}
      },
      "source": [
        "# Confusion matrix over last run test predictions\n",
        "targets = test_dataset.targets\n",
        "preds = all_preds.to('cpu').numpy()\n",
        "\n",
        "plot.heatmap_cm(targets, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5ESzk5gF2c_c",
        "colab": {}
      },
      "source": [
        "def mean_std_scores(train_loss_history, train_accuracy_history,\n",
        "                   val_loss_history, val_accuracy_history, test_accuracy_history):\n",
        "  '''\n",
        "      Average the scores of runs different splits\n",
        "  '''\n",
        "  # keys = 'Split i-esim'\n",
        "  keys = train_loss_history[0].keys()\n",
        "\n",
        "  # Containers for average scores\n",
        "  avg_train_loss = {k:[] for k in keys}\n",
        "  avg_train_accuracy = {k:[] for k in keys}\n",
        "  avg_val_loss = {k:[] for k in keys}\n",
        "  avg_val_accuracy = {k:[] for k in keys}\n",
        "  avg_test_accuracy = {k:[] for k in keys}\n",
        "  \n",
        "  train_loss = []\n",
        "  train_accuracy = []\n",
        "  val_loss = []\n",
        "  val_accuracy = []\n",
        "  test_accuracy = []\n",
        "\n",
        "  for key in keys:\n",
        "    for run in range(NUM_RUNS):\n",
        "\n",
        "      # Append all i-th scores (split i-esim) for the different runs\n",
        "      avg_train_loss[key].append(train_loss_history[run][key])\n",
        "      avg_train_accuracy[key].append(train_accuracy_history[run][key])\n",
        "      avg_val_loss[key].append(val_loss_history[run][key])\n",
        "      avg_val_accuracy[key].append(val_accuracy_history[run][key])\n",
        "      avg_test_accuracy[key].append(test_accuracy_history[run][key])\n",
        "\n",
        "    # Define (mean, std) of the i-th score for each split\n",
        "    train_loss.append([np.array(avg_train_loss[key]).mean(), np.array(avg_train_loss[key]).std()])\n",
        "    train_accuracy.append([np.array(avg_train_accuracy[key]).mean(), np.array(avg_train_accuracy[key]).std()])\n",
        "    val_loss.append([np.array(avg_val_loss[key]).mean(), np.array(avg_val_loss[key]).std()])\n",
        "    val_accuracy.append([np.array(avg_val_accuracy[key]).mean(), np.array(avg_val_accuracy[key]).std()])\n",
        "    test_accuracy.append([np.array(avg_test_accuracy[key]).mean(), np.array(avg_test_accuracy[key]).std()])\n",
        "\n",
        "  train_loss = np.array(train_loss)\n",
        "  train_accuracy = np.array(train_accuracy)\n",
        "  val_loss = np.array(val_loss)\n",
        "  val_accuracy = np.array(val_accuracy)\n",
        "  test_accuracy = np.array(test_accuracy)\n",
        "\n",
        "  # Return averaged scores\n",
        "  return(train_loss, train_accuracy, val_loss, val_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dKCztHSw7lHB",
        "colab": {}
      },
      "source": [
        "# Get the average scores\n",
        "train_loss, train_accuracy, val_loss, val_accuracy,\\\n",
        "test_accuracy = mean_std_scores(train_loss_history, train_accuracy_history,\n",
        "                                   val_loss_history, val_accuracy_history, test_accuracy_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7TAdCtXDEa5d",
        "colab": {}
      },
      "source": [
        "plot.train_val_scores(train_loss, train_accuracy, val_loss, val_accuracy, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E1APlRtTpmkK",
        "colab": {}
      },
      "source": [
        "plot.test_scores(test_accuracy, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dlbZp6TJzuLZ",
        "colab": {}
      },
      "source": [
        "# @todo: create utils package for functions\n",
        "\n",
        "import ast\n",
        "\n",
        "def load_json_scores(root):\n",
        "\n",
        "  with open(os.path.join(root, 'train_accuracy_history.json')) as f:\n",
        "      train_accuracy_history = ast.literal_eval(f.read())\n",
        "\n",
        "  with open(os.path.join(root, 'train_loss_history.json')) as f:\n",
        "      train_loss_history = ast.literal_eval(f.read())\n",
        "\n",
        "  with open(os.path.join(root, 'val_accuracy_history.json')) as f:\n",
        "      val_accuracy_history = ast.literal_eval(f.read())\n",
        "\n",
        "  with open(os.path.join(root, 'val_loss_history.json')) as f:\n",
        "      val_loss_history = ast.literal_eval(f.read())\n",
        "\n",
        "  with open(os.path.join(root, 'test_accuracy_history.json')) as f:\n",
        "      test_accuracy_history = ast.literal_eval(f.read())\n",
        "\n",
        "  return(train_loss_history, train_accuracy_history, val_loss_history,\n",
        "         val_accuracy_history, test_accuracy_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tdI9oGAN3heI",
        "colab": {}
      },
      "source": [
        "# @todo: create utils package for functions\n",
        "import json\n",
        "\n",
        "def save_json_scores(root, train_loss_history, train_accuracy_history,\n",
        "                   val_loss_history, val_accuracy_history, test_accuracy_history):\n",
        "\n",
        "    with open(os.path.join(root, 'train_loss_history.json'), 'w') as fout:\n",
        "        json.dump(train_loss_history, fout)\n",
        "\n",
        "    with open(os.path.join(root, 'train_accuracy_history.json'), 'w') as fout:\n",
        "        json.dump(train_accuracy_history, fout)\n",
        "\n",
        "    with open(os.path.join(root, 'val_loss_history.json'), 'w') as fout:\n",
        "        json.dump(val_loss_history, fout)\n",
        "\n",
        "    with open(os.path.join(root, 'val_accuracy_history.json'), 'w') as fout:\n",
        "        json.dump(val_accuracy_history, fout)\n",
        "\n",
        "    with open(os.path.join(root, 'test_accuracy_history.json'), 'w') as fout:\n",
        "        json.dump(test_accuracy_history, fout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S_ZTJSSRd_Ea",
        "colab": {}
      },
      "source": [
        "save_json_scores('scores', train_loss_history, train_accuracy_history,\n",
        "                   val_loss_history, val_accuracy_history, test_accuracy_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QnBlpXBme3L-",
        "colab": {}
      },
      "source": [
        "!zip -r scores.zip scores\n",
        "files.download(\"scores.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJ_Z48QmQ2C",
        "colab_type": "text"
      },
      "source": [
        "## Learning Without Forgetting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERL_PF-cm1N_",
        "colab_type": "text"
      },
      "source": [
        "### Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JHBfXPTXm16d",
        "colab": {}
      },
      "source": [
        "# Directories\n",
        "DATA_DIR = 'data'       # Directory where the dataset will be downloaded\n",
        "\n",
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Dataset\n",
        "RANDOM_STATE = 420      # For reproducibility of results\n",
        "                        # Note: different random states give very different\n",
        "                        # splits and therefore very different results.\n",
        "\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "NUM_BATCHES = 10\n",
        "CLASS_BATCH_SIZE = 10   # Size of batch of classes for incremental learning\n",
        "\n",
        "VAL_SIZE = 0.1          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 128        # Batch size (iCaRL sets this to 128)\n",
        "LR = 2                  # Initial learning rate\n",
        "                        # iCaRL sets LR = 2. Since they use BinaryCrossEntropy loss it is feasible,\n",
        "                        # in our case it would diverge as we use CrossEntropy loss.\n",
        "MOMENTUM = 0.9          # Momentum for stochastic gradient descent (SGD)\n",
        "WEIGHT_DECAY = 1e-5     # Weight decay from iCaRL\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method\n",
        "                        # Note: this should be at least 3 to have a fair benchmark\n",
        "\n",
        "NUM_EPOCHS = 70         # Total number of training epochs\n",
        "MILESTONES = [49, 63]   # Step down policy from iCaRL (MultiStepLR)\n",
        "                        # Decrease the learning rate by gamma at each milestone\n",
        "GAMMA = 0.2             # Gamma factor from iCaRL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EHqtSdwzm16h"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "373M_sOAm16i",
        "colab": {}
      },
      "source": [
        "# Define transformations for training\n",
        "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define transformations for evaluation\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "97Gi3Sp8m16k",
        "outputId": "cf6f0749-cb02-4390-be3e-43752e77d454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataloaders = [[] for i in range(NUM_RUNS)]\n",
        "val_dataloaders = [[] for i in range(NUM_RUNS)]\n",
        "test_dataloaders = [[] for i in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "\n",
        "  test_subsets = []\n",
        "\n",
        "  for split_i in range(CLASS_BATCH_SIZE):\n",
        "\n",
        "    # Download dataset only at first instantiation\n",
        "    if(run_i+split_i == 0):\n",
        "      download = True\n",
        "    else:\n",
        "      download = False\n",
        "\n",
        "    # Create CIFAR100 dataset\n",
        "    train_dataset = Cifar100(DATA_DIR, train = True, download = download, random_state = RANDOM_STATE+run_i, transform=train_transform)\n",
        "    test_dataset = Cifar100(DATA_DIR, train = False, download = False, random_state = RANDOM_STATE+run_i, transform=test_transform)\n",
        "   \n",
        "    # Subspace of CIFAR100 of 10 classes\n",
        "    train_dataset.set_classes_batch(train_dataset.batch_splits[split_i]) \n",
        "    test_dataset.set_classes_batch([test_dataset.batch_splits[i] for i in range(0, split_i+1)])\n",
        "\n",
        "    # Define train and validation indices\n",
        "    train_indices, val_indices = train_dataset.train_val_split(VAL_SIZE, RANDOM_STATE)\n",
        "    \n",
        "    train_dataloaders[run_i].append(DataLoader(Subset(train_dataset, train_indices), \n",
        "                               batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True))\n",
        "    \n",
        "    val_dataloaders[run_i].append(DataLoader(Subset(train_dataset, val_indices), \n",
        "                                batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True))\n",
        "    \n",
        "    # Dataset with all seen class\n",
        "    test_dataloaders[run_i].append(DataLoader(test_dataset, \n",
        "                               batch_size=BATCH_SIZE, shuffle=True, num_workers=4))           "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ksaz2qZ5m16n",
        "outputId": "7023a762-eed6-4ffc-bd67-a943cab94d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Sanity check: visualize a batch of images\n",
        "dataiter = iter(test_dataloaders[0][5])\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "plot.image_grid(images, one_channel=False)\n",
        "unique_labels = np.unique(labels, return_counts=True)\n",
        "unique_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  6,  7,  8, 10, 12, 14, 15, 16, 17, 18, 20, 22, 23,\n",
              "        24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41,\n",
              "        42, 43, 44, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59]),\n",
              " array([2, 2, 2, 1, 3, 2, 1, 2, 2, 3, 2, 3, 2, 4, 1, 3, 1, 3, 1, 3, 6, 1,\n",
              "        5, 4, 3, 5, 3, 4, 5, 3, 5, 1, 2, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3,\n",
              "        2, 1, 2, 1, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw6a_xAumXQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "'''BCE formulation:\n",
        " let x = logits, z = labels. The logistic loss is\n",
        "\n",
        "  z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n",
        "'''\n",
        "\n",
        "   \n",
        "CLASS_BATCH_SIZE = 10\n",
        "\n",
        "\n",
        "class LWF():\n",
        "  def __init__(self, device, net, old_net, criterion, optimizer, scheduler,\n",
        "               train_dataloader, val_dataloader, test_dataloader, num_classes=10):\n",
        "    \n",
        "    self.device = device\n",
        "\n",
        "    self.net = net\n",
        "    self.best_net = self.net\n",
        "    self.old_net = old_net # None for first ten classes\n",
        "\n",
        "    self.criterion = BCEWithLogitsLoss() # Classifier criterion \n",
        "    self.optimizer = optimizer\n",
        "    self.scheduler = scheduler\n",
        "\n",
        "    self.train_dataloader = train_dataloader\n",
        "    self.val_dataloader = val_dataloader\n",
        "    self.test_dataloader = test_dataloader\n",
        "\n",
        "    self.num_classes = num_classes # can be incremented ouitside methods in the main, or inside methods\n",
        "    self.order = np.arange(100)\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def warm_up():\n",
        "    pass\n",
        "\n",
        "  def increment_classes(self, n=10):\n",
        "    \"\"\"Add n classes in the final fully connected layer.\"\"\"\n",
        "\n",
        "    in_features = self.net.fc.in_features  # size of each input sample\n",
        "    out_features = self.net.fc.out_features  # size of each output sample\n",
        "    weight = self.net.fc.weight.data\n",
        "\n",
        "    self.net.fc = nn.Linear(in_features, out_features+n)\n",
        "    self.net.fc.weight.data[:out_features] = weight\n",
        "\n",
        "  def to_onehot(self, targets): \n",
        "    '''\n",
        "    Args:\n",
        "    targets : dataloader.dataset.targets of the new task images\n",
        "    '''\n",
        "    one_hot_targets = torch.eye(self.num_classes)[targets]\n",
        "\n",
        "    return one_hot_targets.to(self.device)\n",
        "\n",
        "  def do_first_batch(self, batch, labels):\n",
        "\n",
        "    batch = batch.to(self.device)\n",
        "    labels = labels.to(self.device) # new classes labels\n",
        "\n",
        "    # Zero-ing the gradients\n",
        "    self.optimizer.zero_grad()\n",
        "\n",
        "    # One hot encoding of new task labels \n",
        "    one_hot_labels = self.to_onehot(labels) # Size = [128, 10]\n",
        "    \n",
        "\n",
        "    # New net forward pass\n",
        "    outputs = self.net(batch)  \n",
        "    \n",
        "    loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Accuracy over NEW IMAGES, not over all images\n",
        "    running_corrects = \\\n",
        "        torch.sum(preds == labels.data).data.item() # Pu essere che debba usare targets e non labels\n",
        "\n",
        "    # Backward pass: computes gradients\n",
        "    loss.backward()\n",
        "\n",
        "    self.optimizer.step()\n",
        "\n",
        "    return loss, running_corrects\n",
        "\n",
        "\n",
        "  def do_batch(self, batch, labels):\n",
        "\n",
        "    batch = batch.to(self.device)\n",
        "    labels = labels.to(self.device) # new classes labels\n",
        "\n",
        "    # Zero-ing the gradients\n",
        "    self.optimizer.zero_grad()\n",
        "\n",
        "    # One hot encoding of new task labels \n",
        "    one_hot_labels = self.to_onehot(labels) # Size = [128, n_classes] will be sliced as [:, :self.num_classes-10]\n",
        "    new_classes = (self.order[range(self.num_classes-10, self.num_classes)]).astype(np.int32)\n",
        "    one_hot_labels = torch.stack([one_hot_labels[:, i] for i in new_classes], axis=1)\n",
        "\n",
        "    # Old net forward pass\n",
        "    old_outputs = self.sigmoid(self.old_net(batch)) # Size = [128, 100]\n",
        "    old_classes = (self.order[range(self.num_classes-10)]).astype(np.int32)\n",
        "    old_outputs = torch.stack([old_outputs[:, i] for i in old_classes], axis =1)\n",
        "    \n",
        "    # Combine new and old class targets\n",
        "    targets = torch.cat((old_outputs, one_hot_labels), 1)\n",
        "\n",
        "    # New net forward pass\n",
        "    outputs = self.net(batch) # Size = [128, 100] comparable with the define targets\n",
        "    out_classes = (self.order[range(self.num_classes)]).astype(np.int32)\n",
        "    outputs = torch.stack([outputs[:, i] for i in out_classes], axis=1)\n",
        "  \n",
        "    \n",
        "    loss = self.criterion(outputs, targets) # BCE Loss with sigmoids over outputs (over targets must be done manually)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Accuracy over NEW IMAGES, not over all images\n",
        "    running_corrects = \\\n",
        "        torch.sum(preds == labels.data).data.item() \n",
        "\n",
        "    # Backward pass: computes gradients\n",
        "    loss.backward()\n",
        "\n",
        "    self.optimizer.step()\n",
        "\n",
        "    return loss, running_corrects\n",
        "\n",
        "\n",
        "  def do_epoch(self, current_epoch):\n",
        "\n",
        "    self.net.train()\n",
        "\n",
        "    running_train_loss = 0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "    batch_idx = 0\n",
        "\n",
        "    print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")\n",
        "\n",
        "    for images, labels in self.train_dataloader:\n",
        "\n",
        "      if self.num_classes == CLASS_BATCH_SIZE:\n",
        "        loss, corrects = self.do_first_batch(images, labels)\n",
        "      else:\n",
        "        loss, corrects = self.do_batch(images, labels)\n",
        "\n",
        "      running_train_loss += loss.item()\n",
        "      running_corrects += corrects\n",
        "      total += labels.size(0)\n",
        "      batch_idx += 1\n",
        "\n",
        "    self.scheduler.step()\n",
        "\n",
        "    # Calculate average scores\n",
        "    train_loss = running_train_loss / batch_idx # Average over all batches\n",
        "    train_accuracy = running_corrects / float(total) # Average over all samples\n",
        "\n",
        "    print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n",
        "\n",
        "    return (train_loss, train_accuracy)\n",
        "\n",
        "\n",
        "  def train(self, num_epochs):\n",
        "    \"\"\"Train the network for a specified number of epochs, and save\n",
        "    the best performing model on the validation set.\n",
        "    \n",
        "    Args:\n",
        "        num_epochs (int): number of epochs for training the network.\n",
        "    Returns:\n",
        "        train_loss: loss computed on the last epoch\n",
        "        train_accuracy: accuracy computed on the last epoch\n",
        "        val_loss: average loss on the validation set of the last epoch\n",
        "        val_accuracy: accuracy on the validation set of the last epoch\n",
        "    \"\"\"\n",
        "\n",
        "    # @todo: is the return behaviour intended? (scores of the last epoch)\n",
        "\n",
        "    self.net = self.net.to(self.device)\n",
        "    if self.old_net != None:\n",
        "      self.old_net = self.old_net.to(self.device)\n",
        "      self.old_net.train(False)\n",
        "\n",
        "    cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "    self.best_loss = float(\"inf\")\n",
        "    self.best_epoch = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Run an epoch (start counting form 1)\n",
        "        train_loss, train_accuracy = self.do_epoch(epoch+1)\n",
        "    \n",
        "        # Validate after each epoch \n",
        "        val_loss, val_accuracy = self.validate()    \n",
        "\n",
        "        # Best validation model\n",
        "        if val_loss < self.best_loss:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_net = deepcopy(self.net)\n",
        "            self.best_epoch = epoch\n",
        "            print(\"Best model updated\")\n",
        "\n",
        "        print(\"\")\n",
        "\n",
        "    return (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy)\n",
        "\n",
        "\n",
        "  def validate(self):\n",
        "    \"\"\"Validate the model.\n",
        "    \n",
        "    Returns:\n",
        "        val_loss: average loss function computed on the network outputs\n",
        "            of the validation set (val_dataloader).\n",
        "        val_accuracy: accuracy computed on the validation set.\n",
        "    \"\"\"\n",
        "\n",
        "    self.net.train(False)\n",
        "\n",
        "    running_val_loss = 0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "    batch_idx = 0\n",
        "\n",
        "\n",
        "    for batch, labels in self.val_dataloader:\n",
        "      batch = batch.to(self.device)\n",
        "      labels = labels.to(self.device)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # One hot encoding of new task labels \n",
        "      one_hot_labels = self.to_onehot(labels) # Size = [128, 100] will be sliced as [:, :self.num_classes-10]\n",
        "      new_classes = (self.order[range(self.num_classes-10, self.num_classes)]).astype(np.int32)\n",
        "      one_hot_labels = torch.stack([one_hot_labels[:, i] for i in new_classes], axis=1)\n",
        "\n",
        "      if self.num_classes > 10:\n",
        "        # Old net forward pass\n",
        "        old_outputs = self.sigmoid(self.old_net(batch)) # Size = [128, 100]\n",
        "        old_classes = (self.order[range(self.num_classes-10)]).astype(np.int32)\n",
        "        old_outputs = torch.stack([old_outputs[:, i] for i in old_classes], axis =1)\n",
        "\n",
        "        # Combine new and old class targets\n",
        "        targets = torch.cat((old_outputs, one_hot_labels), 1)\n",
        "\n",
        "      else:\n",
        "        targets = one_hot_labels\n",
        "\n",
        "      # New net forward pass\n",
        "      outputs = self.net(batch) # Size = [128, 100] comparable with the define targets\n",
        "      out_classes = (self.order[range(self.num_classes)]).astype(np.int32)\n",
        "      outputs = torch.stack([outputs[:, i] for i in out_classes], axis=1)\n",
        "\n",
        "      \n",
        "      loss = self.criterion(outputs, targets) # BCE Loss with sigmoids over outputs (over targets must be done manually)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update the number of correctly classified validation samples\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      running_val_loss += loss.item()\n",
        "\n",
        "      batch_idx += 1\n",
        "\n",
        "    # Calcuate scores\n",
        "    val_loss = running_val_loss / batch_idx\n",
        "    val_accuracy = running_corrects / float(total)\n",
        "\n",
        "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
        "\n",
        "    return (val_loss, val_accuracy)\n",
        "\n",
        "\n",
        "  def test(self):\n",
        "    \"\"\"Test the model.\n",
        "    Returns:\n",
        "        accuracy (float): accuracy of the model on the test set\n",
        "    \"\"\"\n",
        "\n",
        "    self.best_net.train(False)  # Set Network to evaluation mode\n",
        "\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "\n",
        "    all_preds = torch.tensor([]) # to store all predictions\n",
        "    all_preds = all_preds.type(torch.LongTensor)\n",
        "    \n",
        "    for images, labels in self.test_dataloader:\n",
        "      images = images.to(self.device)\n",
        "      labels = labels.to(self.device)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = self.best_net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # Append batch predictions\n",
        "      all_preds = torch.cat(\n",
        "          (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "      )\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = running_corrects / float(total)  \n",
        "\n",
        "    print(f\"Test accuracy: {accuracy}\")\n",
        "\n",
        "    return (accuracy, all_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlThDLCvXJwS",
        "colab_type": "code",
        "outputId": "dea97966-97f2-427f-e1ab-1c9e99c21192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over runs\n",
        "for train_dataloader, val_dataloader, test_dataloader in zip(train_dataloaders,\n",
        "                                                             val_dataloaders, test_dataloaders):\n",
        "  \n",
        "    \n",
        "    train_loss_history.append({})\n",
        "    train_accuracy_history.append({})\n",
        "    val_loss_history.append({})\n",
        "    val_accuracy_history.append({})\n",
        "    test_accuracy_history.append({})\n",
        "\n",
        "    net = resnet32()  # Define the net\n",
        "    \n",
        "    criterion = nn.BCEWithLogitsLoss()  # Define the loss\n",
        "        \n",
        "    \n",
        "    i = 0\n",
        "    for train_split, val_split, test_split in zip(train_dataloader,\n",
        "                                                  val_dataloader, test_dataloader):\n",
        "      \n",
        "      # Redefine optimizer at each split (pass by reference issue)\n",
        "      parameters_to_optimize = net.parameters()\n",
        "      optimizer = optim.SGD(parameters_to_optimize, lr=LR,\n",
        "                            momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "      scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
        "                                                milestones=MILESTONES, gamma=GAMMA)\n",
        "        \n",
        "      current_split = \"Split %i\"%(i)\n",
        "      print(current_split)\n",
        "\n",
        "      num_classes = CLASS_BATCH_SIZE*(i+1)\n",
        "\n",
        "      if num_classes == CLASS_BATCH_SIZE:\n",
        "        # Old Network = None\n",
        "        lwf = LWF(DEVICE, net, None, criterion, optimizer, scheduler,\n",
        "                          train_split, val_split, test_split, num_classes)\n",
        "      else:\n",
        "        lwf = LWF(DEVICE, net, old_net, criterion, optimizer, scheduler,\n",
        "                        train_split, val_split, test_split, num_classes)\n",
        "        \n",
        "\n",
        "      scores = lwf.train(NUM_EPOCHS)  # train the model\n",
        "\n",
        "      # score[i] = dictionary with key:epoch, value: score\n",
        "      train_loss_history[-1][current_split] = scores[0]\n",
        "      train_accuracy_history[-1][current_split] = scores[1]\n",
        "      val_loss_history[-1][current_split] = scores[2]\n",
        "      val_accuracy_history[-1][current_split] = scores[3]\n",
        "\n",
        "      # Test the model on classes seen until now\n",
        "      test_accuracy, all_preds = lwf.test()\n",
        "\n",
        "      test_accuracy_history[-1][current_split] = test_accuracy\n",
        "\n",
        "      # Uncomment if default resnet has 10 node at last FC layer\n",
        "      old_net = deepcopy(lwf.net)\n",
        "      lwf.increment_classes()\n",
        "\n",
        "      i =i+1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split 0\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.41743720769882203, Train accuracy: 0.1299107142857143\n",
            "Validation loss: 1.2165175278981526, Validation accuracy: 0.11979166666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.3192023975508554, Train accuracy: 0.14330357142857142\n",
            "Validation loss: 0.3183782796065013, Validation accuracy: 0.1484375\n",
            "Best model updated\n",
            "\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.31439777953284126, Train accuracy: 0.16004464285714284\n",
            "Validation loss: 0.3219562868277232, Validation accuracy: 0.109375\n",
            "\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.3124394220965249, Train accuracy: 0.1705357142857143\n",
            "Validation loss: 0.3097195525964101, Validation accuracy: 0.18229166666666666\n",
            "Best model updated\n",
            "\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.3055715790816716, Train accuracy: 0.19933035714285716\n",
            "Validation loss: 0.35315298040707904, Validation accuracy: 0.15104166666666666\n",
            "\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.29491167409079416, Train accuracy: 0.2408482142857143\n",
            "Validation loss: 0.28979726632436115, Validation accuracy: 0.20833333333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.28999285101890565, Train accuracy: 0.24776785714285715\n",
            "Validation loss: 0.2873980800310771, Validation accuracy: 0.2864583333333333\n",
            "Best model updated\n",
            "\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.2855408217225756, Train accuracy: 0.27299107142857143\n",
            "Validation loss: 0.2761689027150472, Validation accuracy: 0.2760416666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.28161630971091134, Train accuracy: 0.2734375\n",
            "Validation loss: 0.2901066541671753, Validation accuracy: 0.2838541666666667\n",
            "\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.2799938891615186, Train accuracy: 0.30111607142857144\n",
            "Validation loss: 0.2892179489135742, Validation accuracy: 0.2682291666666667\n",
            "\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.27246277800628116, Train accuracy: 0.3220982142857143\n",
            "Validation loss: 0.26459216078122455, Validation accuracy: 0.3541666666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.2668221311909812, Train accuracy: 0.34486607142857145\n",
            "Validation loss: 0.2785785297552745, Validation accuracy: 0.3177083333333333\n",
            "\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.2623530025993075, Train accuracy: 0.3587053571428571\n",
            "Validation loss: 0.27610063552856445, Validation accuracy: 0.3151041666666667\n",
            "\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.261776516692979, Train accuracy: 0.37254464285714284\n",
            "Validation loss: 0.26283398270606995, Validation accuracy: 0.390625\n",
            "Best model updated\n",
            "\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.2572384306362697, Train accuracy: 0.38191964285714286\n",
            "Validation loss: 0.2761080463727315, Validation accuracy: 0.3802083333333333\n",
            "\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.2563211500644684, Train accuracy: 0.3950892857142857\n",
            "Validation loss: 0.25632759431997937, Validation accuracy: 0.4140625\n",
            "Best model updated\n",
            "\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.2530244367463248, Train accuracy: 0.40245535714285713\n",
            "Validation loss: 0.2589658002058665, Validation accuracy: 0.3697916666666667\n",
            "\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.24949301949569158, Train accuracy: 0.40982142857142856\n",
            "Validation loss: 0.25385652482509613, Validation accuracy: 0.3958333333333333\n",
            "Best model updated\n",
            "\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.24864501442228046, Train accuracy: 0.4171875\n",
            "Validation loss: 0.2793876727422078, Validation accuracy: 0.4088541666666667\n",
            "\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.24595981027398792, Train accuracy: 0.4294642857142857\n",
            "Validation loss: 0.24810918668905893, Validation accuracy: 0.4140625\n",
            "Best model updated\n",
            "\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.24097581250326974, Train accuracy: 0.44419642857142855\n",
            "Validation loss: 0.35266663630803424, Validation accuracy: 0.2734375\n",
            "\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.23993865081242152, Train accuracy: 0.44040178571428573\n",
            "Validation loss: 0.25497861206531525, Validation accuracy: 0.4088541666666667\n",
            "\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.23149923469339098, Train accuracy: 0.46964285714285714\n",
            "Validation loss: 0.23436901966730753, Validation accuracy: 0.4765625\n",
            "Best model updated\n",
            "\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.22775863579341343, Train accuracy: 0.49129464285714286\n",
            "Validation loss: 0.23927838603655496, Validation accuracy: 0.4739583333333333\n",
            "\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.2213961022240775, Train accuracy: 0.49174107142857143\n",
            "Validation loss: 0.23385869959990183, Validation accuracy: 0.4427083333333333\n",
            "Best model updated\n",
            "\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.22235711557524546, Train accuracy: 0.49642857142857144\n",
            "Validation loss: 0.22435376048088074, Validation accuracy: 0.4817708333333333\n",
            "Best model updated\n",
            "\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.21491631695202418, Train accuracy: 0.5223214285714286\n",
            "Validation loss: 0.24789126217365265, Validation accuracy: 0.484375\n",
            "\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.20959187490599496, Train accuracy: 0.5310267857142857\n",
            "Validation loss: 0.21527386208375296, Validation accuracy: 0.5234375\n",
            "Best model updated\n",
            "\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.20318944539342607, Train accuracy: 0.5508928571428572\n",
            "Validation loss: 0.20597282548745474, Validation accuracy: 0.5494791666666666\n",
            "Best model updated\n",
            "\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.19846973844936916, Train accuracy: 0.5716517857142858\n",
            "Validation loss: 0.20995001991589865, Validation accuracy: 0.5598958333333334\n",
            "\n",
            "Epoch: 31, LR: [2]\n",
            "Train loss: 0.19252147504261563, Train accuracy: 0.5834821428571428\n",
            "Validation loss: 0.2580133080482483, Validation accuracy: 0.4817708333333333\n",
            "\n",
            "Epoch: 32, LR: [2]\n",
            "Train loss: 0.1930518503699984, Train accuracy: 0.5845982142857142\n",
            "Validation loss: 0.2116566300392151, Validation accuracy: 0.546875\n",
            "\n",
            "Epoch: 33, LR: [2]\n",
            "Train loss: 0.18467795423098973, Train accuracy: 0.6084821428571429\n",
            "Validation loss: 0.24691801766554514, Validation accuracy: 0.4661458333333333\n",
            "\n",
            "Epoch: 34, LR: [2]\n",
            "Train loss: 0.18004852533340454, Train accuracy: 0.6149553571428571\n",
            "Validation loss: 0.18260719875494638, Validation accuracy: 0.5859375\n",
            "Best model updated\n",
            "\n",
            "Epoch: 35, LR: [2]\n",
            "Train loss: 0.17198033928871154, Train accuracy: 0.6453125\n",
            "Validation loss: 0.19038390616575876, Validation accuracy: 0.6015625\n",
            "\n",
            "Epoch: 36, LR: [2]\n",
            "Train loss: 0.1686632743903569, Train accuracy: 0.64375\n",
            "Validation loss: 0.19511613746484122, Validation accuracy: 0.5807291666666666\n",
            "\n",
            "Epoch: 37, LR: [2]\n",
            "Train loss: 0.16267950662544794, Train accuracy: 0.6613839285714286\n",
            "Validation loss: 0.167406032482783, Validation accuracy: 0.6380208333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 38, LR: [2]\n",
            "Train loss: 0.1586896308830806, Train accuracy: 0.6736607142857143\n",
            "Validation loss: 0.18045244614283243, Validation accuracy: 0.6432291666666666\n",
            "\n",
            "Epoch: 39, LR: [2]\n",
            "Train loss: 0.15528827330895834, Train accuracy: 0.678125\n",
            "Validation loss: 0.16418810685475668, Validation accuracy: 0.6484375\n",
            "Best model updated\n",
            "\n",
            "Epoch: 40, LR: [2]\n",
            "Train loss: 0.15536693930625917, Train accuracy: 0.6796875\n",
            "Validation loss: 0.19314047197500864, Validation accuracy: 0.6223958333333334\n",
            "\n",
            "Epoch: 41, LR: [2]\n",
            "Train loss: 0.14955872637884957, Train accuracy: 0.6964285714285714\n",
            "Validation loss: 0.20628840227921805, Validation accuracy: 0.578125\n",
            "\n",
            "Epoch: 42, LR: [2]\n",
            "Train loss: 0.15101255902222224, Train accuracy: 0.6883928571428571\n",
            "Validation loss: 0.15536678830782572, Validation accuracy: 0.6796875\n",
            "Best model updated\n",
            "\n",
            "Epoch: 43, LR: [2]\n",
            "Train loss: 0.13798515434776035, Train accuracy: 0.7270089285714286\n",
            "Validation loss: 0.18287288149197897, Validation accuracy: 0.625\n",
            "\n",
            "Epoch: 44, LR: [2]\n",
            "Train loss: 0.13724340732608523, Train accuracy: 0.7261160714285714\n",
            "Validation loss: 0.20491081972916922, Validation accuracy: 0.5911458333333334\n",
            "\n",
            "Epoch: 45, LR: [2]\n",
            "Train loss: 0.13272307025534766, Train accuracy: 0.7323660714285715\n",
            "Validation loss: 0.2092741678158442, Validation accuracy: 0.609375\n",
            "\n",
            "Epoch: 46, LR: [2]\n",
            "Train loss: 0.1346842184662819, Train accuracy: 0.7377232142857143\n",
            "Validation loss: 0.16111890971660614, Validation accuracy: 0.6770833333333334\n",
            "\n",
            "Epoch: 47, LR: [2]\n",
            "Train loss: 0.12655998979296004, Train accuracy: 0.7457589285714286\n",
            "Validation loss: 0.16803060472011566, Validation accuracy: 0.6822916666666666\n",
            "\n",
            "Epoch: 48, LR: [2]\n",
            "Train loss: 0.12536609172821045, Train accuracy: 0.7520089285714285\n",
            "Validation loss: 0.17035416762034097, Validation accuracy: 0.671875\n",
            "\n",
            "Epoch: 49, LR: [2]\n",
            "Train loss: 0.11884390711784362, Train accuracy: 0.7712053571428571\n",
            "Validation loss: 0.16044687728087106, Validation accuracy: 0.6927083333333334\n",
            "\n",
            "Epoch: 50, LR: [0.4]\n",
            "Train loss: 0.10031355023384095, Train accuracy: 0.809375\n",
            "Validation loss: 0.12685421854257584, Validation accuracy: 0.7473958333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 51, LR: [0.4]\n",
            "Train loss: 0.08730495699814388, Train accuracy: 0.8299107142857143\n",
            "Validation loss: 0.10921534895896912, Validation accuracy: 0.7916666666666666\n",
            "Best model updated\n",
            "\n",
            "Epoch: 52, LR: [0.4]\n",
            "Train loss: 0.08356571836130959, Train accuracy: 0.8366071428571429\n",
            "Validation loss: 0.11495380351940791, Validation accuracy: 0.7994791666666666\n",
            "\n",
            "Epoch: 53, LR: [0.4]\n",
            "Train loss: 0.08314299817596163, Train accuracy: 0.8388392857142857\n",
            "Validation loss: 0.12802573293447495, Validation accuracy: 0.7421875\n",
            "\n",
            "Epoch: 54, LR: [0.4]\n",
            "Train loss: 0.08027791029640606, Train accuracy: 0.8542410714285714\n",
            "Validation loss: 0.12260288000106812, Validation accuracy: 0.7630208333333334\n",
            "\n",
            "Epoch: 55, LR: [0.4]\n",
            "Train loss: 0.07545615541083472, Train accuracy: 0.8584821428571429\n",
            "Validation loss: 0.12844679752985635, Validation accuracy: 0.7473958333333334\n",
            "\n",
            "Epoch: 56, LR: [0.4]\n",
            "Train loss: 0.07769874611071177, Train accuracy: 0.8511160714285714\n",
            "Validation loss: 0.12053149690230687, Validation accuracy: 0.7578125\n",
            "\n",
            "Epoch: 57, LR: [0.4]\n",
            "Train loss: 0.07316898810012, Train accuracy: 0.8649553571428571\n",
            "Validation loss: 0.11318048338095348, Validation accuracy: 0.7916666666666666\n",
            "\n",
            "Epoch: 58, LR: [0.4]\n",
            "Train loss: 0.06838662709508624, Train accuracy: 0.8707589285714286\n",
            "Validation loss: 0.11810337503751119, Validation accuracy: 0.78125\n",
            "\n",
            "Epoch: 59, LR: [0.4]\n",
            "Train loss: 0.06908921833549227, Train accuracy: 0.8678571428571429\n",
            "Validation loss: 0.1194221427043279, Validation accuracy: 0.7526041666666666\n",
            "\n",
            "Epoch: 60, LR: [0.4]\n",
            "Train loss: 0.07118677507553782, Train accuracy: 0.8674107142857143\n",
            "Validation loss: 0.10319831967353821, Validation accuracy: 0.8020833333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 61, LR: [0.4]\n",
            "Train loss: 0.06662462034395762, Train accuracy: 0.8770089285714285\n",
            "Validation loss: 0.1247468168536822, Validation accuracy: 0.7760416666666666\n",
            "\n",
            "Epoch: 62, LR: [0.4]\n",
            "Train loss: 0.06545050261276109, Train accuracy: 0.8803571428571428\n",
            "Validation loss: 0.11630187928676605, Validation accuracy: 0.7916666666666666\n",
            "\n",
            "Epoch: 63, LR: [0.4]\n",
            "Train loss: 0.06688801891037396, Train accuracy: 0.8734375\n",
            "Validation loss: 0.13892439504464468, Validation accuracy: 0.7473958333333334\n",
            "\n",
            "Epoch: 64, LR: [0.08000000000000002]\n",
            "Train loss: 0.05917855735336031, Train accuracy: 0.8926339285714285\n",
            "Validation loss: 0.10517104218403499, Validation accuracy: 0.7916666666666666\n",
            "\n",
            "Epoch: 65, LR: [0.08000000000000002]\n",
            "Train loss: 0.05249197802373341, Train accuracy: 0.90625\n",
            "Validation loss: 0.10021861394246419, Validation accuracy: 0.8203125\n",
            "Best model updated\n",
            "\n",
            "Epoch: 66, LR: [0.08000000000000002]\n",
            "Train loss: 0.05227085006024156, Train accuracy: 0.9075892857142858\n",
            "Validation loss: 0.10541727145512898, Validation accuracy: 0.7864583333333334\n",
            "\n",
            "Epoch: 67, LR: [0.08000000000000002]\n",
            "Train loss: 0.05092534869909286, Train accuracy: 0.9084821428571429\n",
            "Validation loss: 0.10443989932537079, Validation accuracy: 0.8046875\n",
            "\n",
            "Epoch: 68, LR: [0.08000000000000002]\n",
            "Train loss: 0.05136469059756824, Train accuracy: 0.9104910714285714\n",
            "Validation loss: 0.117287278175354, Validation accuracy: 0.7630208333333334\n",
            "\n",
            "Epoch: 69, LR: [0.08000000000000002]\n",
            "Train loss: 0.050194927624293735, Train accuracy: 0.9102678571428572\n",
            "Validation loss: 0.10832638045152028, Validation accuracy: 0.8125\n",
            "\n",
            "Epoch: 70, LR: [0.08000000000000002]\n",
            "Train loss: 0.048888923972845076, Train accuracy: 0.9125\n",
            "Validation loss: 0.10197771588961284, Validation accuracy: 0.7994791666666666\n",
            "\n",
            "Test accuracy: 0.771\n",
            "Split 1\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.2615768760442734, Train accuracy: 0.08102678571428572\n",
            "Validation loss: 0.2320014884074529, Validation accuracy: 0.15104166666666666\n",
            "Best model updated\n",
            "\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.20408356700624739, Train accuracy: 0.27388392857142857\n",
            "Validation loss: 0.1964425891637802, Validation accuracy: 0.3307291666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.18955227051462445, Train accuracy: 0.328125\n",
            "Validation loss: 0.18379040559132895, Validation accuracy: 0.3723958333333333\n",
            "Best model updated\n",
            "\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.18385461526257652, Train accuracy: 0.38392857142857145\n",
            "Validation loss: 0.1943505754073461, Validation accuracy: 0.3567708333333333\n",
            "\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.1782960219042642, Train accuracy: 0.4205357142857143\n",
            "Validation loss: 0.17694860200087228, Validation accuracy: 0.4479166666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.17285299173423221, Train accuracy: 0.47299107142857144\n",
            "Validation loss: 0.17204744617144266, Validation accuracy: 0.4479166666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.16925043548856464, Train accuracy: 0.48794642857142856\n",
            "Validation loss: 0.18396673103173575, Validation accuracy: 0.4921875\n",
            "\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.16826439542429789, Train accuracy: 0.5256696428571429\n",
            "Validation loss: 0.1802089661359787, Validation accuracy: 0.5364583333333334\n",
            "\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.16408690214157104, Train accuracy: 0.5421875\n",
            "Validation loss: 0.18973387281099954, Validation accuracy: 0.4401041666666667\n",
            "\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.16205235847405025, Train accuracy: 0.5508928571428572\n",
            "Validation loss: 0.16417503853638968, Validation accuracy: 0.5833333333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.15938134491443634, Train accuracy: 0.5792410714285714\n",
            "Validation loss: 0.17724535862604776, Validation accuracy: 0.4947916666666667\n",
            "\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.15575782103197916, Train accuracy: 0.5921875\n",
            "Validation loss: 0.16932009160518646, Validation accuracy: 0.5390625\n",
            "\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.15582147708960942, Train accuracy: 0.5928571428571429\n",
            "Validation loss: 0.18324329952398935, Validation accuracy: 0.5546875\n",
            "\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.1536995151213237, Train accuracy: 0.6044642857142857\n",
            "Validation loss: 0.1802435020605723, Validation accuracy: 0.5729166666666666\n",
            "\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.15148880907467432, Train accuracy: 0.621875\n",
            "Validation loss: 0.17207090556621552, Validation accuracy: 0.5625\n",
            "\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.1478314140013286, Train accuracy: 0.64375\n",
            "Validation loss: 0.17347347736358643, Validation accuracy: 0.5859375\n",
            "\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.14754658426557268, Train accuracy: 0.6511160714285714\n",
            "Validation loss: 0.17524211605389914, Validation accuracy: 0.5859375\n",
            "\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.14828821207795825, Train accuracy: 0.6553571428571429\n",
            "Validation loss: 0.1860873301823934, Validation accuracy: 0.5651041666666666\n",
            "\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.14577184958117348, Train accuracy: 0.6520089285714286\n",
            "Validation loss: 0.17682246367136636, Validation accuracy: 0.5807291666666666\n",
            "\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.1429781104837145, Train accuracy: 0.6816964285714285\n",
            "Validation loss: 0.19472464422384897, Validation accuracy: 0.4973958333333333\n",
            "\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.14284779876470566, Train accuracy: 0.6814732142857143\n",
            "Validation loss: 0.17165368298689523, Validation accuracy: 0.5494791666666666\n",
            "\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.1408851959875652, Train accuracy: 0.6915178571428572\n",
            "Validation loss: 0.17356549203395844, Validation accuracy: 0.5807291666666666\n",
            "\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.13942624011210034, Train accuracy: 0.6944196428571429\n",
            "Validation loss: 0.17873584727446237, Validation accuracy: 0.5885416666666666\n",
            "\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.14044319689273835, Train accuracy: 0.7029017857142857\n",
            "Validation loss: 0.18253795305887857, Validation accuracy: 0.5963541666666666\n",
            "\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.13953382202557155, Train accuracy: 0.7200892857142858\n",
            "Validation loss: 0.17718927065531412, Validation accuracy: 0.6223958333333334\n",
            "\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.13720657037837164, Train accuracy: 0.7133928571428572\n",
            "Validation loss: 0.18217585980892181, Validation accuracy: 0.609375\n",
            "\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.13530851134232114, Train accuracy: 0.7310267857142857\n",
            "Validation loss: 0.19315957029660544, Validation accuracy: 0.6067708333333334\n",
            "\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.1317127559866224, Train accuracy: 0.7361607142857143\n",
            "Validation loss: 0.18512065708637238, Validation accuracy: 0.6380208333333334\n",
            "\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.13363591602870395, Train accuracy: 0.7410714285714286\n",
            "Validation loss: 0.18217171231905618, Validation accuracy: 0.609375\n",
            "\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.13192041154418674, Train accuracy: 0.7515625\n",
            "Validation loss: 0.17600044111410776, Validation accuracy: 0.6328125\n",
            "\n",
            "Epoch: 31, LR: [2]\n",
            "Train loss: 0.12923144612993512, Train accuracy: 0.7535714285714286\n",
            "Validation loss: 0.1707566430171331, Validation accuracy: 0.6302083333333334\n",
            "\n",
            "Epoch: 32, LR: [2]\n",
            "Train loss: 0.1283629630293165, Train accuracy: 0.7685267857142857\n",
            "Validation loss: 0.19600199162960052, Validation accuracy: 0.5520833333333334\n",
            "\n",
            "Epoch: 33, LR: [2]\n",
            "Train loss: 0.1274630572114672, Train accuracy: 0.7707589285714286\n",
            "Validation loss: 0.17152313391367593, Validation accuracy: 0.6510416666666666\n",
            "\n",
            "Epoch: 34, LR: [2]\n",
            "Train loss: 0.12769182601145335, Train accuracy: 0.76875\n",
            "Validation loss: 0.1889196733633677, Validation accuracy: 0.6380208333333334\n",
            "\n",
            "Epoch: 35, LR: [2]\n",
            "Train loss: 0.12854251606123787, Train accuracy: 0.7696428571428572\n",
            "Validation loss: 0.1950409859418869, Validation accuracy: 0.6223958333333334\n",
            "\n",
            "Epoch: 36, LR: [2]\n",
            "Train loss: 0.12704966983624866, Train accuracy: 0.7823660714285714\n",
            "Validation loss: 0.18946702281634012, Validation accuracy: 0.6197916666666666\n",
            "\n",
            "Epoch: 37, LR: [2]\n",
            "Train loss: 0.12865851159606662, Train accuracy: 0.7703125\n",
            "Validation loss: 0.18639626602331796, Validation accuracy: 0.5833333333333334\n",
            "\n",
            "Epoch: 38, LR: [2]\n",
            "Train loss: 0.12838719423328127, Train accuracy: 0.7870535714285715\n",
            "Validation loss: 0.17071299254894257, Validation accuracy: 0.6458333333333334\n",
            "\n",
            "Epoch: 39, LR: [2]\n",
            "Train loss: 0.12399002994809832, Train accuracy: 0.7897321428571429\n",
            "Validation loss: 0.17030920584996542, Validation accuracy: 0.6666666666666666\n",
            "\n",
            "Epoch: 40, LR: [2]\n",
            "Train loss: 0.12107658748115813, Train accuracy: 0.8064732142857143\n",
            "Validation loss: 0.16906578342119852, Validation accuracy: 0.6744791666666666\n",
            "\n",
            "Epoch: 41, LR: [2]\n",
            "Train loss: 0.12296371928283147, Train accuracy: 0.8011160714285714\n",
            "Validation loss: 0.18010280032952627, Validation accuracy: 0.6588541666666666\n",
            "\n",
            "Epoch: 42, LR: [2]\n",
            "Train loss: 0.12586483848946436, Train accuracy: 0.7872767857142857\n",
            "Validation loss: 0.20112189650535583, Validation accuracy: 0.6171875\n",
            "\n",
            "Epoch: 43, LR: [2]\n",
            "Train loss: 0.12466019966772625, Train accuracy: 0.8091517857142857\n",
            "Validation loss: 0.17357258001963297, Validation accuracy: 0.6536458333333334\n",
            "\n",
            "Epoch: 44, LR: [2]\n",
            "Train loss: 0.12072193196841649, Train accuracy: 0.8158482142857143\n",
            "Validation loss: 0.17266364892323813, Validation accuracy: 0.6380208333333334\n",
            "\n",
            "Epoch: 45, LR: [2]\n",
            "Train loss: 0.11811190588133676, Train accuracy: 0.8241071428571428\n",
            "Validation loss: 0.19420350094636282, Validation accuracy: 0.6119791666666666\n",
            "\n",
            "Epoch: 46, LR: [2]\n",
            "Train loss: 0.11956612084593092, Train accuracy: 0.8055803571428571\n",
            "Validation loss: 0.1747674842675527, Validation accuracy: 0.6484375\n",
            "\n",
            "Epoch: 47, LR: [2]\n",
            "Train loss: 0.11960605531930923, Train accuracy: 0.8185267857142857\n",
            "Validation loss: 0.16822877526283264, Validation accuracy: 0.65625\n",
            "\n",
            "Epoch: 48, LR: [2]\n",
            "Train loss: 0.11924177919115339, Train accuracy: 0.8247767857142857\n",
            "Validation loss: 0.17314582566420236, Validation accuracy: 0.6822916666666666\n",
            "\n",
            "Epoch: 49, LR: [2]\n",
            "Train loss: 0.11725773747478213, Train accuracy: 0.8263392857142857\n",
            "Validation loss: 0.17788160840670267, Validation accuracy: 0.6432291666666666\n",
            "\n",
            "Epoch: 50, LR: [0.4]\n",
            "Train loss: 0.10488073123352869, Train accuracy: 0.8758928571428571\n",
            "Validation loss: 0.1512065331141154, Validation accuracy: 0.6744791666666666\n",
            "Best model updated\n",
            "\n",
            "Epoch: 51, LR: [0.4]\n",
            "Train loss: 0.09771569413798196, Train accuracy: 0.896875\n",
            "Validation loss: 0.14454608658949533, Validation accuracy: 0.7161458333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 52, LR: [0.4]\n",
            "Train loss: 0.09563844289098467, Train accuracy: 0.9075892857142858\n",
            "Validation loss: 0.15457414587338766, Validation accuracy: 0.7135416666666666\n",
            "\n",
            "Epoch: 53, LR: [0.4]\n",
            "Train loss: 0.09509611598082951, Train accuracy: 0.9075892857142858\n",
            "Validation loss: 0.15004073083400726, Validation accuracy: 0.6927083333333334\n",
            "\n",
            "Epoch: 54, LR: [0.4]\n",
            "Train loss: 0.09291218455348696, Train accuracy: 0.9185267857142857\n",
            "Validation loss: 0.1483092655738195, Validation accuracy: 0.7109375\n",
            "\n",
            "Epoch: 55, LR: [0.4]\n",
            "Train loss: 0.09230857576642718, Train accuracy: 0.9225446428571429\n",
            "Validation loss: 0.1492744783560435, Validation accuracy: 0.7135416666666666\n",
            "\n",
            "Epoch: 56, LR: [0.4]\n",
            "Train loss: 0.09265902553285871, Train accuracy: 0.9227678571428571\n",
            "Validation loss: 0.1464166740576426, Validation accuracy: 0.734375\n",
            "\n",
            "Epoch: 57, LR: [0.4]\n",
            "Train loss: 0.09162810359682355, Train accuracy: 0.9229910714285714\n",
            "Validation loss: 0.15824413299560547, Validation accuracy: 0.7083333333333334\n",
            "\n",
            "Epoch: 58, LR: [0.4]\n",
            "Train loss: 0.09109567425080708, Train accuracy: 0.93125\n",
            "Validation loss: 0.1511125514904658, Validation accuracy: 0.7317708333333334\n",
            "\n",
            "Epoch: 59, LR: [0.4]\n",
            "Train loss: 0.09156675040721893, Train accuracy: 0.9296875\n",
            "Validation loss: 0.15786349276701608, Validation accuracy: 0.7057291666666666\n",
            "\n",
            "Epoch: 60, LR: [0.4]\n",
            "Train loss: 0.09068757231746401, Train accuracy: 0.934375\n",
            "Validation loss: 0.15177378555138907, Validation accuracy: 0.734375\n",
            "\n",
            "Epoch: 61, LR: [0.4]\n",
            "Train loss: 0.09137334802321025, Train accuracy: 0.9283482142857142\n",
            "Validation loss: 0.1668983449538549, Validation accuracy: 0.703125\n",
            "\n",
            "Epoch: 62, LR: [0.4]\n",
            "Train loss: 0.09028797830854143, Train accuracy: 0.9401785714285714\n",
            "Validation loss: 0.15939784546693167, Validation accuracy: 0.6953125\n",
            "\n",
            "Epoch: 63, LR: [0.4]\n",
            "Train loss: 0.08982828280755452, Train accuracy: 0.9352678571428571\n",
            "Validation loss: 0.16590635478496552, Validation accuracy: 0.7005208333333334\n",
            "\n",
            "Epoch: 64, LR: [0.08000000000000002]\n",
            "Train loss: 0.08859254441090993, Train accuracy: 0.9390625\n",
            "Validation loss: 0.16021316746870676, Validation accuracy: 0.703125\n",
            "\n",
            "Epoch: 65, LR: [0.08000000000000002]\n",
            "Train loss: 0.08729048371315003, Train accuracy: 0.9448660714285714\n",
            "Validation loss: 0.14870505531628928, Validation accuracy: 0.7291666666666666\n",
            "\n",
            "Epoch: 66, LR: [0.08000000000000002]\n",
            "Train loss: 0.08729617893695832, Train accuracy: 0.9401785714285714\n",
            "Validation loss: 0.1562076061964035, Validation accuracy: 0.7109375\n",
            "\n",
            "Epoch: 67, LR: [0.08000000000000002]\n",
            "Train loss: 0.08804615885019303, Train accuracy: 0.9417410714285714\n",
            "Validation loss: 0.16390339533487955, Validation accuracy: 0.7057291666666666\n",
            "\n",
            "Epoch: 68, LR: [0.08000000000000002]\n",
            "Train loss: 0.08762145191431045, Train accuracy: 0.9484375\n",
            "Validation loss: 0.15600288410981497, Validation accuracy: 0.6927083333333334\n",
            "\n",
            "Epoch: 69, LR: [0.08000000000000002]\n",
            "Train loss: 0.08662798958165305, Train accuracy: 0.9450892857142857\n",
            "Validation loss: 0.15812513728936514, Validation accuracy: 0.7161458333333334\n",
            "\n",
            "Epoch: 70, LR: [0.08000000000000002]\n",
            "Train loss: 0.08762136782918657, Train accuracy: 0.9491071428571428\n",
            "Validation loss: 0.14589720964431763, Validation accuracy: 0.7395833333333334\n",
            "\n",
            "Test accuracy: 0.622\n",
            "Split 2\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.221830586876188, Train accuracy: 0.0265625\n",
            "Validation loss: 0.19652548929055533, Validation accuracy: 0.033854166666666664\n",
            "Best model updated\n",
            "\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.17944842193807875, Train accuracy: 0.08415178571428572\n",
            "Validation loss: 0.1804884374141693, Validation accuracy: 0.10677083333333333\n",
            "Best model updated\n",
            "\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.1698965528181621, Train accuracy: 0.16049107142857144\n",
            "Validation loss: 0.17538648347059885, Validation accuracy: 0.17447916666666666\n",
            "Best model updated\n",
            "\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.16638022703783853, Train accuracy: 0.19642857142857142\n",
            "Validation loss: 0.18110856910546622, Validation accuracy: 0.21614583333333334\n",
            "\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.16413073199135916, Train accuracy: 0.22611607142857143\n",
            "Validation loss: 0.17279928922653198, Validation accuracy: 0.2604166666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.16171267969267708, Train accuracy: 0.2560267857142857\n",
            "Validation loss: 0.16824976603190103, Validation accuracy: 0.2890625\n",
            "Best model updated\n",
            "\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.1594365601028715, Train accuracy: 0.2857142857142857\n",
            "Validation loss: 0.16986899077892303, Validation accuracy: 0.3046875\n",
            "\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.15762491268771037, Train accuracy: 0.31205357142857143\n",
            "Validation loss: 0.17100301384925842, Validation accuracy: 0.3463541666666667\n",
            "\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.15555774526936667, Train accuracy: 0.34330357142857143\n",
            "Validation loss: 0.17297252515951791, Validation accuracy: 0.3072916666666667\n",
            "\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.15486378031117576, Train accuracy: 0.35625\n",
            "Validation loss: 0.1662768671909968, Validation accuracy: 0.3359375\n",
            "Best model updated\n",
            "\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.15179334368024552, Train accuracy: 0.38125\n",
            "Validation loss: 0.17562313874562582, Validation accuracy: 0.359375\n",
            "\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.1521643579006195, Train accuracy: 0.40379464285714284\n",
            "Validation loss: 0.16988330086072287, Validation accuracy: 0.3932291666666667\n",
            "\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.1510753835950579, Train accuracy: 0.42611607142857144\n",
            "Validation loss: 0.17656203111012778, Validation accuracy: 0.3645833333333333\n",
            "\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.14863324080194745, Train accuracy: 0.4390625\n",
            "Validation loss: 0.17584983507792154, Validation accuracy: 0.3828125\n",
            "\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.14749731166022165, Train accuracy: 0.48013392857142856\n",
            "Validation loss: 0.17182327310244241, Validation accuracy: 0.4244791666666667\n",
            "\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.14663795615945543, Train accuracy: 0.4796875\n",
            "Validation loss: 0.17653015752633414, Validation accuracy: 0.4010416666666667\n",
            "\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.14541636407375336, Train accuracy: 0.5109375\n",
            "Validation loss: 0.17828284204006195, Validation accuracy: 0.4088541666666667\n",
            "\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.14507109820842742, Train accuracy: 0.5165178571428571\n",
            "Validation loss: 0.18172037104765573, Validation accuracy: 0.4088541666666667\n",
            "\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.1453565946647099, Train accuracy: 0.5350446428571428\n",
            "Validation loss: 0.1738054503997167, Validation accuracy: 0.515625\n",
            "\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.14355982584612711, Train accuracy: 0.5470982142857143\n",
            "Validation loss: 0.17361894249916077, Validation accuracy: 0.4791666666666667\n",
            "\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.14145559753690448, Train accuracy: 0.5727678571428572\n",
            "Validation loss: 0.18043892085552216, Validation accuracy: 0.4869791666666667\n",
            "\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.14173748748643059, Train accuracy: 0.5763392857142857\n",
            "Validation loss: 0.17489476998647055, Validation accuracy: 0.4765625\n",
            "\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.1413594079869134, Train accuracy: 0.5787946428571429\n",
            "Validation loss: 0.1772190729777018, Validation accuracy: 0.5104166666666666\n",
            "\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.14147084823676517, Train accuracy: 0.5993303571428571\n",
            "Validation loss: 0.1726424147685369, Validation accuracy: 0.5052083333333334\n",
            "\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.1376922471182687, Train accuracy: 0.6165178571428571\n",
            "Validation loss: 0.1885218620300293, Validation accuracy: 0.4947916666666667\n",
            "\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.1370649957231113, Train accuracy: 0.6232142857142857\n",
            "Validation loss: 0.17578395704428354, Validation accuracy: 0.4713541666666667\n",
            "\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.13600021196263176, Train accuracy: 0.6497767857142858\n",
            "Validation loss: 0.19126717249552408, Validation accuracy: 0.4973958333333333\n",
            "\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.13876696910176958, Train accuracy: 0.6453125\n",
            "Validation loss: 0.2094344049692154, Validation accuracy: 0.421875\n",
            "\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.13767021383558, Train accuracy: 0.6450892857142857\n",
            "Validation loss: 0.17763405044873556, Validation accuracy: 0.5\n",
            "\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.1353559413126537, Train accuracy: 0.6823660714285714\n",
            "Validation loss: 0.1772762288649877, Validation accuracy: 0.5130208333333334\n",
            "\n",
            "Epoch: 31, LR: [2]\n",
            "Train loss: 0.1339165055326053, Train accuracy: 0.6799107142857143\n",
            "Validation loss: 0.17540690302848816, Validation accuracy: 0.5078125\n",
            "\n",
            "Epoch: 32, LR: [2]\n",
            "Train loss: 0.13461059140307563, Train accuracy: 0.6834821428571428\n",
            "Validation loss: 0.18246775368849436, Validation accuracy: 0.5364583333333334\n",
            "\n",
            "Epoch: 33, LR: [2]\n",
            "Train loss: 0.13311806065695628, Train accuracy: 0.6890625\n",
            "Validation loss: 0.18874155978361765, Validation accuracy: 0.5364583333333334\n",
            "\n",
            "Epoch: 34, LR: [2]\n",
            "Train loss: 0.13330238802092417, Train accuracy: 0.7024553571428571\n",
            "Validation loss: 0.18516900142033896, Validation accuracy: 0.5546875\n",
            "\n",
            "Epoch: 35, LR: [2]\n",
            "Train loss: 0.1336910984345845, Train accuracy: 0.7098214285714286\n",
            "Validation loss: 0.1784272144238154, Validation accuracy: 0.5651041666666666\n",
            "\n",
            "Epoch: 36, LR: [2]\n",
            "Train loss: 0.13014873393944332, Train accuracy: 0.7180803571428571\n",
            "Validation loss: 0.19504761695861816, Validation accuracy: 0.5286458333333334\n",
            "\n",
            "Epoch: 37, LR: [2]\n",
            "Train loss: 0.13139346220663617, Train accuracy: 0.7194196428571429\n",
            "Validation loss: 0.1840530385573705, Validation accuracy: 0.5182291666666666\n",
            "\n",
            "Epoch: 38, LR: [2]\n",
            "Train loss: 0.1321342504450253, Train accuracy: 0.7265625\n",
            "Validation loss: 0.1938049097855886, Validation accuracy: 0.5364583333333334\n",
            "\n",
            "Epoch: 39, LR: [2]\n",
            "Train loss: 0.13136184407132012, Train accuracy: 0.7254464285714286\n",
            "Validation loss: 0.19581621388594309, Validation accuracy: 0.5286458333333334\n",
            "\n",
            "Epoch: 40, LR: [2]\n",
            "Train loss: 0.1296760897551264, Train accuracy: 0.7444196428571429\n",
            "Validation loss: 0.18325642247994742, Validation accuracy: 0.5729166666666666\n",
            "\n",
            "Epoch: 41, LR: [2]\n",
            "Train loss: 0.1284148082137108, Train accuracy: 0.7457589285714286\n",
            "Validation loss: 0.1774223248163859, Validation accuracy: 0.578125\n",
            "\n",
            "Epoch: 42, LR: [2]\n",
            "Train loss: 0.12828054875135422, Train accuracy: 0.7649553571428571\n",
            "Validation loss: 0.20619449019432068, Validation accuracy: 0.5598958333333334\n",
            "\n",
            "Epoch: 43, LR: [2]\n",
            "Train loss: 0.1316806069442204, Train accuracy: 0.7497767857142857\n",
            "Validation loss: 0.1801718274752299, Validation accuracy: 0.5651041666666666\n",
            "\n",
            "Epoch: 44, LR: [2]\n",
            "Train loss: 0.1302679594073977, Train accuracy: 0.7549107142857143\n",
            "Validation loss: 0.18823237220446268, Validation accuracy: 0.546875\n",
            "\n",
            "Epoch: 45, LR: [2]\n",
            "Train loss: 0.13052021179880416, Train accuracy: 0.7595982142857143\n",
            "Validation loss: 0.19186274210611978, Validation accuracy: 0.5520833333333334\n",
            "\n",
            "Epoch: 46, LR: [2]\n",
            "Train loss: 0.12658418055091586, Train accuracy: 0.7861607142857143\n",
            "Validation loss: 0.18200408418973288, Validation accuracy: 0.546875\n",
            "\n",
            "Epoch: 47, LR: [2]\n",
            "Train loss: 0.12517483915601457, Train accuracy: 0.7917410714285714\n",
            "Validation loss: 0.18915551404158273, Validation accuracy: 0.5651041666666666\n",
            "\n",
            "Epoch: 48, LR: [2]\n",
            "Train loss: 0.12636150760310036, Train accuracy: 0.7821428571428571\n",
            "Validation loss: 0.2070989062388738, Validation accuracy: 0.5625\n",
            "\n",
            "Epoch: 49, LR: [2]\n",
            "Train loss: 0.12513158385242734, Train accuracy: 0.7930803571428572\n",
            "Validation loss: 0.20227311054865518, Validation accuracy: 0.5130208333333334\n",
            "\n",
            "Epoch: 50, LR: [0.4]\n",
            "Train loss: 0.11708890816995075, Train accuracy: 0.8241071428571428\n",
            "Validation loss: 0.16333864629268646, Validation accuracy: 0.5729166666666666\n",
            "Best model updated\n",
            "\n",
            "Epoch: 51, LR: [0.4]\n",
            "Train loss: 0.11161056075777326, Train accuracy: 0.8622767857142857\n",
            "Validation loss: 0.16714773575464884, Validation accuracy: 0.6223958333333334\n",
            "\n",
            "Epoch: 52, LR: [0.4]\n",
            "Train loss: 0.10917946717568806, Train accuracy: 0.8792410714285714\n",
            "Validation loss: 0.1683272272348404, Validation accuracy: 0.6328125\n",
            "\n",
            "Epoch: 53, LR: [0.4]\n",
            "Train loss: 0.10865329248564584, Train accuracy: 0.8881696428571428\n",
            "Validation loss: 0.16652017831802368, Validation accuracy: 0.6067708333333334\n",
            "\n",
            "Epoch: 54, LR: [0.4]\n",
            "Train loss: 0.10788739877087729, Train accuracy: 0.8926339285714285\n",
            "Validation loss: 0.16618277629216513, Validation accuracy: 0.6067708333333334\n",
            "\n",
            "Epoch: 55, LR: [0.4]\n",
            "Train loss: 0.10659496464899608, Train accuracy: 0.8899553571428571\n",
            "Validation loss: 0.16715335349241892, Validation accuracy: 0.5833333333333334\n",
            "\n",
            "Epoch: 56, LR: [0.4]\n",
            "Train loss: 0.10702855778591973, Train accuracy: 0.8875\n",
            "Validation loss: 0.1589722583691279, Validation accuracy: 0.6692708333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 57, LR: [0.4]\n",
            "Train loss: 0.10708711636917932, Train accuracy: 0.8962053571428571\n",
            "Validation loss: 0.16730554898579916, Validation accuracy: 0.6119791666666666\n",
            "\n",
            "Epoch: 58, LR: [0.4]\n",
            "Train loss: 0.10644179050411497, Train accuracy: 0.8950892857142857\n",
            "Validation loss: 0.1655688633521398, Validation accuracy: 0.609375\n",
            "\n",
            "Epoch: 59, LR: [0.4]\n",
            "Train loss: 0.10559483213084085, Train accuracy: 0.9004464285714285\n",
            "Validation loss: 0.16831205288569132, Validation accuracy: 0.609375\n",
            "\n",
            "Epoch: 60, LR: [0.4]\n",
            "Train loss: 0.10661046483686992, Train accuracy: 0.8991071428571429\n",
            "Validation loss: 0.1759777069091797, Validation accuracy: 0.6197916666666666\n",
            "\n",
            "Epoch: 61, LR: [0.4]\n",
            "Train loss: 0.10609473139047623, Train accuracy: 0.8966517857142857\n",
            "Validation loss: 0.16891948878765106, Validation accuracy: 0.5963541666666666\n",
            "\n",
            "Epoch: 62, LR: [0.4]\n",
            "Train loss: 0.10571103777204241, Train accuracy: 0.9069196428571429\n",
            "Validation loss: 0.17258297403653464, Validation accuracy: 0.5807291666666666\n",
            "\n",
            "Epoch: 63, LR: [0.4]\n",
            "Train loss: 0.10467299095221928, Train accuracy: 0.9064732142857143\n",
            "Validation loss: 0.1703153004248937, Validation accuracy: 0.5989583333333334\n",
            "\n",
            "Epoch: 64, LR: [0.08000000000000002]\n",
            "Train loss: 0.10464106798171997, Train accuracy: 0.9196428571428571\n",
            "Validation loss: 0.17018786072731018, Validation accuracy: 0.6223958333333334\n",
            "\n",
            "Epoch: 65, LR: [0.08000000000000002]\n",
            "Train loss: 0.10436894404036658, Train accuracy: 0.9133928571428571\n",
            "Validation loss: 0.16674346228440604, Validation accuracy: 0.6458333333333334\n",
            "\n",
            "Epoch: 66, LR: [0.08000000000000002]\n",
            "Train loss: 0.1039228203041213, Train accuracy: 0.9178571428571428\n",
            "Validation loss: 0.16758185625076294, Validation accuracy: 0.6458333333333334\n",
            "\n",
            "Epoch: 67, LR: [0.08000000000000002]\n",
            "Train loss: 0.10355267311845506, Train accuracy: 0.9285714285714286\n",
            "Validation loss: 0.16813243428866068, Validation accuracy: 0.6354166666666666\n",
            "\n",
            "Epoch: 68, LR: [0.08000000000000002]\n",
            "Train loss: 0.10371570906468801, Train accuracy: 0.9174107142857143\n",
            "Validation loss: 0.16743521392345428, Validation accuracy: 0.640625\n",
            "\n",
            "Epoch: 69, LR: [0.08000000000000002]\n",
            "Train loss: 0.10385131644351142, Train accuracy: 0.9127232142857142\n",
            "Validation loss: 0.17045336465040842, Validation accuracy: 0.6354166666666666\n",
            "\n",
            "Epoch: 70, LR: [0.08000000000000002]\n",
            "Train loss: 0.1033166908792087, Train accuracy: 0.921875\n",
            "Validation loss: 0.16952337324619293, Validation accuracy: 0.6041666666666666\n",
            "\n",
            "Test accuracy: 0.49166666666666664\n",
            "Split 3\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.2053950275693621, Train accuracy: 0.02142857142857143\n",
            "Validation loss: 0.18235205113887787, Validation accuracy: 0.08854166666666667\n",
            "Best model updated\n",
            "\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.16666032033307213, Train accuracy: 0.10669642857142857\n",
            "Validation loss: 0.16386492053667703, Validation accuracy: 0.13802083333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.1583169034549168, Train accuracy: 0.1546875\n",
            "Validation loss: 0.15763744215170541, Validation accuracy: 0.19270833333333334\n",
            "Best model updated\n",
            "\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.15540369493620737, Train accuracy: 0.190625\n",
            "Validation loss: 0.1584369738896688, Validation accuracy: 0.21875\n",
            "\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.1523421198129654, Train accuracy: 0.23504464285714285\n",
            "Validation loss: 0.1616345743338267, Validation accuracy: 0.22916666666666666\n",
            "\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.1515616110392979, Train accuracy: 0.25870535714285714\n",
            "Validation loss: 0.15388056635856628, Validation accuracy: 0.2630208333333333\n",
            "Best model updated\n",
            "\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.1497636684349605, Train accuracy: 0.2908482142857143\n",
            "Validation loss: 0.15667433043320975, Validation accuracy: 0.25\n",
            "\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.1479579814842769, Train accuracy: 0.31919642857142855\n",
            "Validation loss: 0.15536023179690042, Validation accuracy: 0.3411458333333333\n",
            "\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.14625876333032337, Train accuracy: 0.3430803571428571\n",
            "Validation loss: 0.15512052675088248, Validation accuracy: 0.3203125\n",
            "\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.14661580409322467, Train accuracy: 0.3613839285714286\n",
            "Validation loss: 0.16308179994424185, Validation accuracy: 0.2994791666666667\n",
            "\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.14610890873840876, Train accuracy: 0.38571428571428573\n",
            "Validation loss: 0.15797999004522958, Validation accuracy: 0.3463541666666667\n",
            "\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.14394219986030032, Train accuracy: 0.4154017857142857\n",
            "Validation loss: 0.16236401597658792, Validation accuracy: 0.40625\n",
            "\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.1419695075069155, Train accuracy: 0.43325892857142856\n",
            "Validation loss: 0.15823669731616974, Validation accuracy: 0.3776041666666667\n",
            "\n",
            "Epoch: 14, LR: [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-429214a0f54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;31m# score[i] = dictionary with key:epoch, value: score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-53b2ad9fdcf1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# Run an epoch (start counting form 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Validate after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-53b2ad9fdcf1>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(self, current_epoch)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_first_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-53b2ad9fdcf1>\u001b[0m in \u001b[0;36mdo_batch\u001b[0;34m(self, batch, labels)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# Old net forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mold_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Size = [128, 100]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mold_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mold_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mold_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/resnet_cifar.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/resnet_cifar.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}